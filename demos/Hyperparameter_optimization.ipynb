{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization\n",
    "## Iterative approach with GridSearchCV and RandomForestClassifier\n",
    "\n",
    "## <font color=blue> Demo Supercomputing 2019 </font>\n",
    "\n",
    "### PyCOMPSs + Dislib + Fault tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are going to perform a number of **GridSearchCV** with **RandomForestClassifier** in order to evaluate a set of **Hyperparameters**.\n",
    "\n",
    "The main idea is to perform a Grid Search over a small set of hyperparameters (with low granularity) and get its accuracy, and repeat this proces over sets of higher granularity. This process is parallelized with **PyCOMPSs** considering that a task is a **GridSearchCV** with **RandomForestClassifier** for a given set of hyperparameters, which returns its accuracy and the best hyperparameter configuration.\n",
    "\n",
    "Since the algorithm starts with low granularity, and continues with higher granularity, the number of tasks increases, and we can compare the current accuracy with the previous hyperparameters. This fact enables us to consider the possibility of deciding if continuing analysing the hyperparameter sets with higher granularity or not. It can be achieved thanks to the COMPSs **Fault tolerance** mechanism, whose behaviour can be defined by the user within the **@task** decorator with the **on_failure** parameter.\n",
    "\n",
    "First of all, start the COMPSs runtime. Graph generation and Tracing are activated to see the final DAG and trace. These postmortem information enables us to see how the *Fault Tolerance* mechanisms have been applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pycompss.interactive as ipycompss\n",
    "if 'BINDER_SERVICE_HOST' in os.environ:\n",
    "    ipycompss.start(project_xml='../xml/project.xml',\n",
    "                    resources_xml='../xml/resources.xml')\n",
    "else:\n",
    "    ipycompss.start(graph=True, trace=False, monitor=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import **PyCOMPSs** task decorator and synchronization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycompss.api.task import task\n",
    "from pycompss.api.on_failure import on_failure\n",
    "from pycompss.api.api import compss_wait_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Scykit-learn datasets module.\n",
    "\n",
    "Import the **Dislib** required functions to perform *GridSearchCV* with *RandomForestClassfier*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import dislib as ds\n",
    "import numpy as np\n",
    "from dislib.classification import RandomForestClassifier\n",
    "from dislib.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the estimators that are going to be applied per level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "dot = Digraph()\n",
    "dot.node('A', '(1, 32, 64)')\n",
    "dot.node('B', '(2, 16, 31)')\n",
    "dot.node('C', '(33, 48, 63)')\n",
    "dot.node('D', '(3, 9, 15)')\n",
    "dot.node('E', '(17, 23, 30)')\n",
    "dot.node('F', '(34, 40, 47)')\n",
    "dot.node('G', '(49, 55, 62)')\n",
    "dot.node('H', '(4, 5, 6, 7, 8)')\n",
    "dot.node('I', '(10, 11, 12, 13, 14)')\n",
    "dot.node('J', '(18, 19, 20, 21, 22)')\n",
    "dot.node('K', '(24, 25, 26, 27, 28, 29)')\n",
    "dot.node('L', '(35, 36, 37, 38, 39)')\n",
    "dot.node('M', '(41, 42, 43, 44, 45, 46)')\n",
    "dot.node('N', '(50, 51, 52, 53, 54)')\n",
    "dot.node('O', '(56, 57, 58, 59, 60, 61)')\n",
    "dot.edges(['AB', 'AC', 'BD', 'BE', 'CF', 'CG', 'DH', 'DI', 'EJ', 'EK', 'FL', 'FM', 'GN', 'GO'])\n",
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {'level_1': [(1, 32, 64)],\n",
    "              'level_2': [(2, 16, 31), (33, 48, 63)],\n",
    "              'level_3': [[(3, 9, 15), (17, 23, 30)], \n",
    "                          [(34, 40, 47), (49, 55, 62)]],\n",
    "              'level_4': [[[(4, 5, 6, 7, 8), (10, 11, 12, 13, 14)], \n",
    "                           [(18, 19, 20, 21, 22), (24, 25, 26, 27, 28, 29)]],\n",
    "                          [[(35, 36, 37, 38, 39), (41, 42, 43, 44, 45, 46)], \n",
    "                           [(50, 51, 52, 53, 54), (56, 57, 58, 59, 60, 61)]]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the task that will perform the **GridSearchCV** with **RandomForestClassfier** for the given hyperparameters.\n",
    "It also receives the previous score to decide if raising an exception or the result is better that the previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@on_failure(management='CANCEL_SUCCESSORS')\n",
    "@task(returns=2)\n",
    "def evaluate(x_dsarray, y_dsarray, estimators, previous_score):\n",
    "    parameters = {'n_estimators': estimators,\n",
    "                  'max_depth': range(2, 4)}\n",
    "    rf = RandomForestClassifier()\n",
    "    searcher = GridSearchCV(rf, parameters, cv=5)\n",
    "    np.random.seed(5)\n",
    "    searcher.fit(x_dsarray, y_dsarray)\n",
    "    print(str(searcher.best_params_) + \" \" + str(searcher.best_score_))\n",
    "    if searcher.best_score_ < previous_score:\n",
    "        raise Exception(\"The score achieved is worse than the previous\")\n",
    "    return searcher.best_params_, searcher.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the main code iterates over the estimators (hyperparameters) per levels, requesting the *evaluate* task per hyperparameter set. The main dependency among these tasks is the previous score (**partialX** where *X* is the level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = datasets.load_iris(return_X_y=True)\n",
    "x_dsarray = ds.array(x, (30, 4))\n",
    "y_dsarray = ds.array(y[:, np.newaxis], (30, 1))\n",
    "params = []\n",
    "results = []\n",
    "i = 0\n",
    "for l1 in estimators['level_1']:\n",
    "    params1, partial1 = evaluate(x_dsarray, y_dsarray, l1, 0.9)\n",
    "    results.append(('L1', params1, partial1))\n",
    "    j = 0\n",
    "    for l2 in estimators['level_2']:\n",
    "        params2, partial2 = evaluate(x_dsarray, y_dsarray, l2, partial1)\n",
    "        results.append(('L2', params2, partial2))\n",
    "        k = 0\n",
    "        for l3 in estimators['level_3'][j]:\n",
    "            params3, partial3 = evaluate(x_dsarray, y_dsarray, l3, partial2)\n",
    "            results.append(('L3', params3, partial3))\n",
    "            for l4 in estimators['level_4'][j][k]:\n",
    "                results.append(['L4'] + list(evaluate(x_dsarray, y_dsarray, l4, partial3)))\n",
    "            k += 1\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = 0\n",
    "cancelled = 0\n",
    "for i, result in enumerate(results):\n",
    "    l = result[0]\n",
    "    p = compss_wait_on(result[1])\n",
    "    r = compss_wait_on(result[2])\n",
    "    results[i] = (l, p, r) # round(r, 2))\n",
    "    if p and r:\n",
    "        ok += 1\n",
    "    else:\n",
    "        result = None\n",
    "        results[i] = result\n",
    "        cancelled +=1\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "print(\"OK: \" + str(ok))\n",
    "print(\"Cancelled: \" + str(cancelled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results achieved with the graph, and represent in <font color=red> red </font> the tasks that have been cancelled. The tasks that have finished successfully and achieved a good score are shown in <font color=green> green </font> with the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = Digraph()\n",
    "Cancelled_color = 'red'\n",
    "Ok_color ='green'\n",
    "field = 2\n",
    "dot.node('A', str(results[0][field]) if results[0] else \"X\", style='filled', fillcolor=Ok_color if results[0] else Cancelled_color)\n",
    "dot.node('B', str(results[1][field]) if results[1] else \"X\", style='filled', fillcolor=Ok_color if results[1] else Cancelled_color)\n",
    "dot.node('C', str(results[8][field]) if results[8] else \"X\", style='filled', fillcolor=Ok_color if results[8] else Cancelled_color)\n",
    "dot.node('D', str(results[2][field]) if results[2] else \"X\", style='filled', fillcolor=Ok_color if results[2] else Cancelled_color)\n",
    "dot.node('E', str(results[5][field]) if results[5] else \"X\", style='filled', fillcolor=Ok_color if results[5] else Cancelled_color)\n",
    "dot.node('F', str(results[9][field]) if results[9] else \"X\", style='filled', fillcolor=Ok_color if results[9] else Cancelled_color)\n",
    "dot.node('G', str(results[12][field]) if results[12] else \"X\", style='filled', fillcolor=Ok_color if results[12] else Cancelled_color)\n",
    "dot.node('H', str(results[3][field]) if results[3] else \"X\", style='filled', fillcolor=Ok_color if results[3] else Cancelled_color)\n",
    "dot.node('I', str(results[4][field]) if results[4] else \"X\", style='filled', fillcolor=Ok_color if results[4] else Cancelled_color)\n",
    "dot.node('J', str(results[6][field]) if results[6] else \"X\", style='filled', fillcolor=Ok_color if results[6] else Cancelled_color)\n",
    "dot.node('K', str(results[7][field]) if results[7] else \"X\", style='filled', fillcolor=Ok_color if results[7] else Cancelled_color)\n",
    "dot.node('L', str(results[10][field]) if results[10] else \"X\", style='filled', fillcolor=Ok_color if results[10] else Cancelled_color)\n",
    "dot.node('M', str(results[11][field]) if results[11] else \"X\", style='filled', fillcolor=Ok_color if results[11] else Cancelled_color)\n",
    "dot.node('N', str(results[13][field]) if results[13] else \"X\", style='filled', fillcolor=Ok_color if results[13] else Cancelled_color)\n",
    "dot.node('O', str(results[14][field]) if results[14] else \"X\", style='filled', fillcolor=Ok_color if results[14] else Cancelled_color)\n",
    "dot.edges(['AB', 'AC', 'BD', 'BE', 'CF', 'CG', 'DH', 'DI', 'EJ', 'EK', 'FL', 'FM', 'GN', 'GO'])\n",
    "dot\n",
    "# dot.render('graph2', view=False) # To save into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipycompss.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
